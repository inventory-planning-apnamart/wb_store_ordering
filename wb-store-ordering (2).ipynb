{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajawLrQWBrJS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import gspread\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from datetime import datetime as dt\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from googleapiclient.http import MediaFileUpload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_name = 'WB'\n",
        "state_full_name = 'West Bengal'\n",
        "warehouse_id_1 = 8\n",
        "warehouse_id_2 = 10"
      ],
      "metadata": {
        "id": "7EJIx6NWmIr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To add multiple stores to migration_store_list write store_name followed by \",\"\n",
        "\n",
        "migration_store_list = \"\"\"\n",
        "    'AM Serampore Kol', 'AM Gopalpur ASL'\n",
        "\"\"\"\n",
        "\n",
        "# To add multiple store_id just write multiple case statement like CASE WHEN old_store_id THEN new_store_id\n",
        "\n",
        "proxy_store_id = \"\"\"\n",
        "  WHEN a.store_id = 301 THEN 329\n",
        "  WHEN a.store_id = 264 THEN 326\n",
        "\"\"\"\n",
        "\n",
        "# To add multiple store_name just write multiple case statement like CASE WHEN old_store_name THEN new_store_name\n",
        "\n",
        "proxy_store_name = \"\"\"\n",
        "  WHEN c.name = 'AM Serampore Kol' THEN 'AM NEW SERAMPORE KOL'\n",
        "  WHEN c.name = 'AM Gopalpur ASL' THEN 'AM New Gopalpur ASL'\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "d8-CaGo97X1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGUfhldroGdd"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ 1. Load credentials from environment variable (set in GitHub Secrets)\n",
        "secret_string = os.environ.get(\"GSPREAD_CREDENTIALS\")\n",
        "if secret_string is None:\n",
        "    raise ValueError(\"‚ùå GSPREAD_CREDENTIALS secret not set in GitHub Actions\")\n",
        "\n",
        "info_dict = json.loads(secret_string)\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "    \"https://www.googleapis.com/auth/drive\"\n",
        "    \"https://www.googleapis.com/auth/bigquery"\n"
        "]\n",
        "creds = service_account.Credentials.from_service_account_info(info_dict, scopes=SCOPES)\n",
        "\n",
        "# ‚úÖ 2. Authorize gspread\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ 3. Open the Google Sheet\n",
        "workbook = gc.open(f\"Automated Store Ordering {state_name} PY - 2\")\n",
        "\n",
        "# ‚úÖ 4. Used here for bigquery\n",
        "client = bigquery.Client(credentials=creds, project=creds.project_id)\n",
        "\n",
        "# ‚úÖ 5. Used here for Drive API\n",
        "# drive_service = build(\"drive\", \"v3\", credentials=creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclusion store from 60 DOH Capping\n",
        "\n",
        "exclusion_stores = ['AM Barasat KOL', 'AM Sonar Mandir HM KOL', 'AM Ashoknagar Klg KOL', 'AM Uttarpara GT Rd KOL', 'AM Guma KOL']"
      ],
      "metadata": {
        "id": "kMOv8F9eFb6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmrwrY3A-kcX"
      },
      "outputs": [],
      "source": [
        "def repeat_stores(input_list, n):\n",
        "    # Convert the list to a numpy array\n",
        "    array = np.array(input_list)\n",
        "\n",
        "    # Using numpy's repeat function to repeat each element\n",
        "    repeated_array = np.repeat(array, n, 0)\n",
        "\n",
        "    return repeated_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikFuxgwUBR7U"
      },
      "outputs": [],
      "source": [
        "def mround(number, multiple):\n",
        "  return round(number / multiple + 0.0001) * multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEQKYsp1Zk-Q"
      },
      "outputs": [],
      "source": [
        "def makeOrder(curre_qty, ars, tres_doh, tar_doh, modi_mbq, mrq, ct_name, st_name):\n",
        "    # Equation 1: MBQ + DOH with 1\n",
        "    if ct_name == 'Sankranti':\n",
        "        if (curre_qty / ars) > tres_doh and curre_qty >= modi_mbq:\n",
        "            return 0\n",
        "        else:\n",
        "            return mround(\n",
        "                math.ceil(\n",
        "                    max(((tar_doh - (curre_qty / ars)) * ars) - 0.00001,\n",
        "                        (max(modi_mbq, mrq) - curre_qty)) / 2\n",
        "                ) * 2,\n",
        "                mrq\n",
        "            )\n",
        "\n",
        "    # Equation 2: MBQ Only\n",
        "    elif ct_name in ['clip_strip', 'bcd', 'super_deals', 'wow_week', 'mt', 'mt_ad_hoc', 'visibility', 'gift', 'focus_skus', 'asm']:\n",
        "        mbq_only = max(math.ceil(((modi_mbq - curre_qty) / mrq) - 0.00001) * mrq, 0)\n",
        "\n",
        "        # Apply safeguard if DOH >= 60\n",
        "        if (mbq_only + curre_qty) / ars >= 60 and st_name not in exclusion_stores and ct_name not in ['mt', 'visibility', 'gift']:\n",
        "            if curre_qty == 0:\n",
        "                return 2\n",
        "            elif (curre_qty / ars) >= 60:\n",
        "                return 0\n",
        "            else:\n",
        "                return math.ceil(max(((60 - (curre_qty / ars)) * ars) - 0.00001, 1))\n",
        "        else:\n",
        "            return mbq_only\n",
        "\n",
        "    # Equation 3: MBQ + DOH with 1.5\n",
        "    else:\n",
        "        if (curre_qty / ars) > tres_doh and curre_qty >= (modi_mbq / 1.5):\n",
        "            return 0\n",
        "        else:\n",
        "            final_qty = mround(\n",
        "                math.ceil(\n",
        "                    max(((tar_doh - (curre_qty / ars)) * ars) - 0.00001,\n",
        "                        (max(modi_mbq, mrq) - curre_qty)) / 2\n",
        "                ) * 2,\n",
        "                mrq\n",
        "            )\n",
        "\n",
        "            # Apply safeguard if DOH >= 60\n",
        "            if (final_qty + curre_qty) / ars >= 60 and st_name not in exclusion_stores and ct_name not in ['loose']:\n",
        "                if curre_qty == 0:\n",
        "                    return 2\n",
        "                elif (curre_qty / ars) >= 60:\n",
        "                    return 0\n",
        "                else:\n",
        "                    return math.ceil(max(((60 - (curre_qty / ars)) * ars) - 0.00001, 1))\n",
        "            else:\n",
        "                return final_qty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udRmzRYNQLUJ"
      },
      "outputs": [],
      "source": [
        "def cal_thres(beat,tar,cat):\n",
        "  if cat == 'fmcg_a' or cat == 'fmcg_b' or cat == 'fmcg_c' or cat == 'staples_a' or cat == 'staples_b' or cat == 'staples_c' or cat == 'gm_a' or cat == 'gm_b' or cat == 'gm_c' or cat == 'loose' or cat == 'jit' or cat == 'jit-k' or cat == 'summer' or cat == 'btl' or cat == 'npi' or cat == 'clip_strip' or cat == 'bcd' or cat == 'super_deals' or cat == 'wow_week' or cat == 'mt' or cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'gift' or cat == 'focus_skus' or cat == 'asm' or cat == 'allocation' or cat == 'depletion':\n",
        "    return beat + tar\n",
        "  # elif cat in ('non-core'):\n",
        "  #   return round(tar/2)\n",
        "  else:\n",
        "    return beat + 3\n",
        "\n",
        "def cal_tar(thres,tar,cat):\n",
        "  # if cat == 'fmcg_head' or cat == 'staples' or cat == 'staples_jit' or cat == 'loose':\n",
        "  if cat == 'fmcg_a' or cat == 'fmcg_b' or cat == 'fmcg_c' or cat == 'staples_a' or cat == 'staples_b' or cat == 'staples_c' or cat == 'gm_a' or cat == 'gm_b' or cat == 'gm_c' or cat == 'loose' or cat == 'jit' or cat == 'jit-k' or cat == 'summer' or cat == 'btl' or cat == 'npi' or cat == 'clip_strip' or cat == 'bcd' or cat == 'super_deals' or cat == 'wow_week' or cat == 'mt' or cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'gift' or cat == 'focus_skus' or cat == 'asm' or cat == 'allocation' or cat == 'depletion':\n",
        "    return thres\n",
        "  # elif cat in ('non-core'):\n",
        "  #   return tar\n",
        "  else:\n",
        "    return thres + tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umY3Z__RC1gd"
      },
      "outputs": [],
      "source": [
        "def cal_mbq(multiplier, mbq, cat):\n",
        "  if cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'loose':\n",
        "    return mbq\n",
        "  elif cat == 'gift':\n",
        "    return round(multiplier*mbq,1)\n",
        "  else:\n",
        "    return mround((multiplier*mbq),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoEnvBAcQYEr"
      },
      "outputs": [],
      "source": [
        "def dfCreator(cat_df,cat_name):\n",
        "  # creating store x item list\n",
        "\n",
        "  if cat_name == 'mt_ad_hoc' or cat_name == 'visibility' or cat_name == 'gift':\n",
        "    joined_df1 = cat_df\n",
        "  else:\n",
        "    st_details = cat_df.loc[:,[\"tez_id\",\"samaan_id\",\"store_name\",\"beat_gap\",\"multiplier\"]]\n",
        "    st_details = st_details[st_details['tez_id'] != 0]\n",
        "    it_details = cat_df.loc[:,[\"item_code\",\"target_doh\",\"mbq\"]]\n",
        "    it_details = it_details[it_details['item_code'] != 0]\n",
        "    st_half = pd.DataFrame(repeat_stores(st_details,it_details.shape[0]),columns=st_details.columns)\n",
        "    it_half = pd.DataFrame(np.tile(np.array(it_details),(st_details.shape[0],1)),columns=it_details.columns)\n",
        "    joined_df1 = st_half.join(it_half)\n",
        "\n",
        "\n",
        "  joined_df1['type'] = cat_name\n",
        "  joined_df1['multiplier'] = joined_df1['multiplier'].apply(lambda x: np.around(x,1))\n",
        "  joined_df1['mod_mbq'] = joined_df1.apply(lambda x: cal_mbq(x['multiplier'],x['mbq'],cat_name),axis=1)\n",
        "  joined_df1 = pd.merge(joined_df1,mrq_df2.loc[:,['item_code','display_name','min_replenish_qty']],on=['item_code'],how='left')\n",
        "  print('merge 1')\n",
        "  joined_df1 = pd.merge(joined_df1,inv_df2,on=['store_name','item_code'],how='left')\n",
        "  print('merge 2')\n",
        "  transit_df2.rename(columns={'name':'store_name'},inplace=True)\n",
        "  joined_df1 = pd.merge(joined_df1,transit_df2.loc[:,['store_name','item_code','process_qty']],on=['store_name','item_code'],how='left')\n",
        "  print('merge 3')\n",
        "  # cart_df.rename(columns={'store_id':'samaan_id'},inplace=True)\n",
        "  # joined_df1 = pd.merge(joined_df1,cart_df2,on=['samaan_id','item_code'],how='left')\n",
        "  print('merge 4')\n",
        "  joined_df1 = pd.merge(joined_df1,avl_df2,left_on=['tez_id','item_code'],right_on=['store_id','item_code'],how='left')\n",
        "  print('merge 5')\n",
        "  joined_df1.drop(columns=['store_id'],inplace=True)\n",
        "  joined_df1['curr_qty'] = joined_df1['curr_qty'].fillna(0)\n",
        "  joined_df1['process_qty'] = joined_df1['process_qty'].fillna(0)\n",
        "  # joined_df1['order_qty'] = joined_df1['order_qty'].fillna(0)\n",
        "  joined_df1['count_avl_days'] = joined_df1['count_avl_days'].fillna(0.01)\n",
        "  joined_df1['count_avl_days'] = joined_df1['count_avl_days'].apply(lambda x: 15 if x < 15 else x)\n",
        "  joined_df1['last_30daysales'] = joined_df1['last_30daysales'].fillna(0.01)\n",
        "  joined_df1['last_30daysales'] = joined_df1['last_30daysales'].apply(lambda x: x if x > 0 else 0.01)\n",
        "  # joined_df1 = joined_df1.assign(all_qty=lambda row: row['curr_qty'] + row['process_qty'] + row['order_qty']) # Calculating All qty\n",
        "  joined_df1 = joined_df1.assign(all_qty=lambda row: row['curr_qty'] + row['process_qty']) # Calculating All qty\n",
        "  joined_df1 = joined_df1.assign(curr_doh=lambda row: row['curr_qty']/(row['last_30daysales']/row['count_avl_days'])) # Calculating curr DOH\n",
        "  # joined_df1.drop(columns=['curr_qty','process_qty','order_qty'],inplace=True) # Removing Extra Columns\n",
        "  joined_df1.drop(columns=['curr_qty','process_qty'],inplace=True) # Removing Extra Columns\n",
        "  joined_df1 = joined_df1.assign(ARS=lambda x: x['last_30daysales']/x['count_avl_days'])\n",
        "  joined_df1['ARS'] = joined_df1['ARS'].apply(lambda x: max(x,0.01))\n",
        "\n",
        "  # Calculating Threshold and Target DOH\n",
        "\n",
        "  joined_df1['threshold_doh'] = joined_df1.apply(lambda x: cal_thres(x['beat_gap'],x['target_doh'],cat_name),axis=1)\n",
        "  joined_df1['target_doh'] = joined_df1.apply(lambda x: cal_tar(x['threshold_doh'],x['target_doh'],cat_name) ,axis=1)\n",
        "  joined_df1 = pd.merge(joined_df1,wh_df2.loc[:,['sku_code','wh_qty']],left_on=['item_code'],right_on=['sku_code'],how='left')\n",
        "  print('merge 6')\n",
        "  joined_df1['wh_qty'] = joined_df1['wh_qty'].fillna(0)\n",
        "\n",
        "  # print(joined_df1)\n",
        "  joined_df1['order'] = joined_df1.apply(lambda x: makeOrder(x['all_qty'],x['ARS'],x['threshold_doh'],x['target_doh'],x['mod_mbq'],x['min_replenish_qty'],cat_name,x['store_name']),axis=1)\n",
        "\n",
        "  # return joined_df1[joined_df1['order'] != 0].loc[:,['item_code','store_name','order','type']]\n",
        "  # return joined_df1[joined_df1['order'] != 0]\n",
        "  return joined_df1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL76Nl_2_2sB"
      },
      "outputs": [],
      "source": [
        "# Ordering sheet selections by the user\n",
        "gids = {\n",
        "        ##### Main Assortment #####\n",
        "\n",
        "        'fmcg_a':2140842897,\n",
        "        'fmcg_b':1459512030,\n",
        "        'fmcg_c':1024514954,\n",
        "        'staples_a':686195830,\n",
        "        'staples_b':2098196922,\n",
        "        'staples_c':965871084,\n",
        "        'gm_a':1645717487,\n",
        "        'gm_b':941148715,\n",
        "        'gm_c':314829402,\n",
        "        'loose':53967786,\n",
        "        'jit':197437796,\n",
        "        'jit-k':1553249338,\n",
        "\n",
        "        ##### Temp Assortment #####\n",
        "\n",
        "        'clip_strip':55763387,\n",
        "        'bcd':279157190,\n",
        "        'visibility':1994951969,\n",
        "        'gift':1080084985,\n",
        "        'npi':788140546,\n",
        "        'summer':168005917,\n",
        "        'asm':2075309652,\n",
        "        'focus_skus':960399022,\n",
        "\n",
        "      # 'btl':0,\n",
        "      # 'super_deals':360075548,\n",
        "      # 'wow_week':2111882564,\n",
        "      # 'mt':440498050,\n",
        "      # 'mt_ad_hoc':913226990,\n",
        "      # 'allocation':341955460,\n",
        "      # 'depletion':1974209973\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wh_gids = {\n",
        "        ##### Main Assortment #####\n",
        "\n",
        "        'fmcg_a':2140842897,\n",
        "        'fmcg_b':1459512030,\n",
        "        'fmcg_c':1024514954,\n",
        "        'staples_a':686195830,\n",
        "        'staples_b':2098196922,\n",
        "        'staples_c':965871084,\n",
        "        'gm_a':1645717487,\n",
        "        'gm_b':941148715,\n",
        "        'gm_c':314829402,\n",
        "        'loose':53967786,\n",
        "        'jit':197437796,\n",
        "        'jit-k':1553249338,\n",
        "\n",
        "        ##### Temp Assortment #####\n",
        "\n",
        "        'clip_strip':55763387,\n",
        "        'bcd':279157190,\n",
        "        'npi':788140546,\n",
        "        'summer':168005917,\n",
        "        'asm':2075309652,\n",
        "        'focus_skus':960399022,\n",
        "\n",
        "      # 'btl':0,\n",
        "      # 'super_deals':360075548,\n",
        "      # 'wow_week':2111882564,\n",
        "      # 'mt':440498050,\n",
        "      # 'mt_ad_hoc':913226990,\n",
        "      # 'visibility':1994951969,\n",
        "      # 'gift':1080084985,\n",
        "      # 'allocation':341955460,\n",
        "      # 'depletion':1974209973\n",
        "        }"
      ],
      "metadata": {
        "id": "PCBVoBtsLYLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataBase Inputs"
      ],
      "metadata": {
        "id": "R17u4AdWeZtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inventory FOCO Query"
      ],
      "metadata": {
        "id": "zsxLKJtVo5-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  inv_df2 = pd.read_csv('input inventory of foco.csv')\n",
        "  print('input taken')\n",
        "except:\n",
        "  inv_df2 = client.query(f'''\n",
        "    WITH base_data AS (\n",
        "        WITH sales_data AS (\n",
        "            SELECT\n",
        "                c.name,\n",
        "                a.item_code,\n",
        "                GREATEST(SUM(a.qty-a.return_qty),((SUM(CASE WHEN DATE(a.created_at) >= CURRENT_DATE - INTERVAL '6' DAY AND DATE(a.created_at) < CURRENT_DATE - INTERVAL '3' DAY THEN a.qty - a.return_qty ELSE 0 END)+\n",
        "                SUM(CASE WHEN DATE(a.created_at) >= CURRENT_DATE - INTERVAL '13' DAY AND DATE(a.created_at) < CURRENT_DATE - INTERVAL '10' DAY THEN a.qty - a.return_qty ELSE 0 END) +\n",
        "                SUM(CASE WHEN DATE(a.created_at) >= CURRENT_DATE - INTERVAL '20' DAY AND DATE(a.created_at) < CURRENT_DATE - INTERVAL '17' DAY THEN a.qty - a.return_qty ELSE 0 END))*3)) as sales\n",
        "            FROM\n",
        "                apna-mart-data.tezpublic.apnasales_salesbillitem a\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic.apnasales_salesbill b ON a.bill_no = b.bill_no\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic.apnastore_store c ON CAST(b.store_id AS INT) = c.id\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic._apnabase_address d ON c.address_id = d.id\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic._apnabase_state e ON d.state_code = e.code\n",
        "            WHERE\n",
        "                e.name = '{state_full_name}'\n",
        "            AND\n",
        "                b.payment_status = 'RCD'\n",
        "            AND\n",
        "                DATE(a.created_at) >= CURRENT_DATE - 30\n",
        "            GROUP BY\n",
        "                c.name, a.item_code\n",
        "        ),\n",
        "        store_inventory AS (\n",
        "            SELECT\n",
        "                b.name,\n",
        "                a.item_code,\n",
        "                SUM(a.curr_qty) AS curr_qty\n",
        "            FROM\n",
        "                apna-mart-data.tezpublic.apnainventory_stocks a\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic.apnastore_store b ON b.id = CAST(a.store_id AS INT)\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic._apnabase_address c ON b.address_id = c.id\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.tezpublic._apnabase_state d ON c.state_code = d.code\n",
        "            WHERE\n",
        "                a.curr_qty > 0\n",
        "            AND\n",
        "                b.active = TRUE\n",
        "            AND\n",
        "                d.name = '{state_full_name}'\n",
        "            AND\n",
        "                b.name NOT IN ({migration_store_list})\n",
        "            AND\n",
        "                (DATE(expiry_date) >= CURRENT_DATE + 3 OR expiry_date IS NULL)\n",
        "            GROUP BY\n",
        "                b.name, a.item_code\n",
        "        )\n",
        "        SELECT\n",
        "            COALESCE(a.name, b.name) AS name,\n",
        "            COALESCE(a.item_code, b.item_code) AS item_code,\n",
        "            COALESCE(a.sales, 0) AS last_30daysales,\n",
        "            COALESCE(b.curr_qty, 0) AS curr_qty\n",
        "        FROM\n",
        "            sales_data a\n",
        "        FULL OUTER JOIN\n",
        "            store_inventory b ON a.name = b.name AND a.item_code = b.item_code\n",
        "    )\n",
        "    SELECT\n",
        "        CASE {proxy_store_name} ELSE c.name END AS store_name,\n",
        "        c.item_code,\n",
        "        SUM(c.last_30daysales) AS last_30daysales,\n",
        "        SUM(c.curr_qty) AS curr_qty\n",
        "    FROM\n",
        "        base_data c\n",
        "    GROUP BY\n",
        "        store_name, item_code\n",
        "  ''').to_dataframe()"
      ],
      "metadata": {
        "id": "EFou1oBqdl-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Available Days Query"
      ],
      "metadata": {
        "id": "T1ooJgv4qgb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  avl_df2 = pd.read_csv('input available days of foco.csv')\n",
        "  print('input taken')\n",
        "except:\n",
        "  avl_df2 = client.query(f'''\n",
        "    SELECT\n",
        "        a.item_code,\n",
        "        a.store_id,\n",
        "        CASE\n",
        "            WHEN COUNT(a.dump_date) <= 15 THEN 15\n",
        "            ELSE COUNT(a.dump_date)\n",
        "        END AS count_avl_days\n",
        "    FROM\n",
        "        (\n",
        "            SELECT\n",
        "                a.dump_date,\n",
        "                CASE {proxy_store_id} ELSE a.store_id END AS store_id,\n",
        "                a.item_code,\n",
        "                SUM(CASE WHEN a.dump_date > c.closing_date THEN 0 ELSE a.curr_qty END) AS current_qty\n",
        "            FROM\n",
        "                apna-mart-data.smpublic.tezinventoryhistory a\n",
        "            LEFT JOIN\n",
        "                apna-mart-data.smpublic.smstore_franchiseestore c ON a.store_id = CAST(c.pos_store_id AS INT)\n",
        "            WHERE\n",
        "                a.curr_qty > 0\n",
        "            AND\n",
        "                c.state = '{state_full_name}'\n",
        "            AND\n",
        "                a.dump_date BETWEEN  CURRENT_DATE - INTERVAL 30 DAY AND CURRENT_DATE\n",
        "            GROUP BY\n",
        "                a.dump_date, a.store_id, a.item_code\n",
        "            HAVING\n",
        "                SUM(CASE WHEN a.dump_date > c.closing_date THEN 0 ELSE a.curr_qty END) > 0\n",
        "        ) a\n",
        "    GROUP BY\n",
        "        a.item_code, a.store_id\n",
        "  ''').to_dataframe()"
      ],
      "metadata": {
        "id": "Msm-2M8DqsWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-Cart Items Query"
      ],
      "metadata": {
        "id": "LGKoIrzkuoK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cart_df2 = client.query('''\n",
        "  SELECT c.item_code,\n",
        "  c.display_name,\n",
        "  a.store_id as samaan_id,\n",
        "  a.pending_reason,\n",
        "  DATE(a.created_at + MAKE_INTERVAL(minute=>330)) AS created_at,\n",
        "  a.requested_qty,\n",
        "  a.order_qty,\n",
        "  a.order_qty*a.selling as value,\n",
        "  c.brand,\n",
        "  a.status,\n",
        "  b.name\n",
        "FROM `apna-mart-data.smpublic.smorder_franchiseeorderproduct` a\n",
        "LEFT JOIN `apna-mart-data.smpublic.smstore_franchiseestore` b on a.store_id = b.id\n",
        "LEFT JOIN `apna-mart-data.smpublic.smpcm_product` c on a.product_id = c.id\n",
        "LEFT JOIN `apna-mart-data.smpublic.smpcm_productcategory` d on c.category_id = d.id\n",
        "\n",
        "-- where a.pending_reason in ('OOS','OSCL')\n",
        "WHERE\n",
        "  (a.status in ('REQ','ORD') or\n",
        "    (a.status in ('PD') AND a.pending_reason in ('OOS','OSCL','CL'))\n",
        "  )\n",
        "  --  and date(a.created_at + (330 || ' minutes') ::interval) >= CURRENT_DATE-30\n",
        "  and (a.warehouse_id = 8 OR a.warehouse_id = 10)\n",
        "\n",
        "-- and b.id in ('257')\n",
        "-- limit 10\n",
        "''').to_dataframe()"
      ],
      "metadata": {
        "id": "BuTk8wACunyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-Transit Items Query"
      ],
      "metadata": {
        "id": "Cd9dXXBJy96n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  transit_df2 = pd.read_csv('input in-transit items of foco.csv')\n",
        "  print('input taken')\n",
        "except:\n",
        "  transit_df2 = client.query('''\n",
        "  (SELECT\n",
        "      pr.item_code,\n",
        "      pr.display_name,\n",
        "      str.name,\n",
        "      str.id as store_id,\n",
        "      'to be billed' as status,\n",
        "      sum(fop.requested_qty) as process_qty,\n",
        "      sum(fop.cost * fop.requested_qty) as total_value\n",
        "    FROM `apna-mart-data.smpublic.smorder_franchiseeorderproduct` fop\n",
        "    LEFT JOIN `apna-mart-data.smpublic.smpcm_product` pr ON pr.id =fop.product_id\n",
        "    LEFT JOIN `apna-mart-data.smpublic.smstore_franchiseestore` str ON fop.store_id=str.id\n",
        "    WHERE\n",
        "      fop.status IN ('PRC','ORD')\n",
        "    AND\n",
        "      str.state = 'West Bengal'\n",
        "    GROUP BY 1,2,3,4,5\n",
        "  )\n",
        "\n",
        "  UNION DISTINCT\n",
        "\n",
        "  (SELECT\n",
        "      pr.item_code,\n",
        "      pr.display_name,\n",
        "      str.name,\n",
        "      str.id as store_id,\n",
        "      CASE\n",
        "        WHEN fb.status in ('RST','DEL') THEN 'pending receiving'\n",
        "      ELSE 'pending delivery'\n",
        "      END as status,\n",
        "      SUM(fbp.quantity),\n",
        "      SUM(fbp.net_amount)\n",
        "    FROM `apna-mart-data.smpublic.smsales_franchiseebillproduct` fbp\n",
        "    LEFT JOIN `apna-mart-data.smpublic.smsales_franchiseebill` fb on fbp.bill_id=fb.id\n",
        "    LEFT JOIN `apna-mart-data.smpublic.smpcm_product` pr on pr.id =fbp.product_id\n",
        "    LEFT JOIN `apna-mart-data.smpublic.smstore_franchiseestore` str on fb.store_id=str.id\n",
        "    WHERE str.state = 'West Bengal'\n",
        "    AND fb.status NOT IN ('RCD', 'CAN')\n",
        "    AND DATE(fbp.created_at, 'Asia/Kolkata') BETWEEN CURRENT_DATE - INTERVAL 4 DAY AND CURRENT_DATE\n",
        "    GROUP BY 1,2,3,4,5\n",
        "  )\n",
        "  ''').to_dataframe()"
      ],
      "metadata": {
        "id": "kKS0ImN7y9sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRQ+Price Query"
      ],
      "metadata": {
        "id": "ApNVAirG2VV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mrq_df2 = client.query('''\n",
        "SELECT A.item_code,\n",
        " A.display_name,\n",
        " coalesce(AB1.min_replenish_qty,1) min_replenish_qty,\n",
        "#  AB1.case_qty,\n",
        " AB1.product_id,\n",
        " AB1.brand,\n",
        " AB1.name,\n",
        " AB1.level_code ,\n",
        " AB1.cost_price,\n",
        " coalesce(AB1.selling_price,A.mrp*0.9) selling_price ,\n",
        " coalesce(AB1.mrp,A.mrp) mrp,\n",
        " x.name as Sub_category\n",
        "FROM `apna-mart-data.smpublic.smpcm_product` A\n",
        "LEFT JOIN\n",
        "        (SELECT\n",
        "          b.item_code,\n",
        "          b.display_name,\n",
        "          d.min_replenish_qty ,\n",
        "          # d.case_qty,\n",
        "          d.product_id,\n",
        "          b.brand,\n",
        "          c.name,\n",
        "          a.level_code ,\n",
        "          a.cost_price,\n",
        "          a.selling_price,\n",
        "          a.mrp\n",
        "        FROM `apna-mart-data.smpublic.smpricing_latestproductpricingtracker` a\n",
        "        LEFT JOIN  `apna-mart-data.smpublic.smpcm_product` b on a.product = b.id\n",
        "        LEFT JOIN `apna-mart-data.smpublic.smpcm_productcategory` c on b.category_id = c.id\n",
        "        LEFT JOIN `apna-mart-data.smpublic.smwims_warehouseproductcontrol` d on b.id = d.product_id\n",
        "        where a.level_code = 'WRHS_10'\n",
        "        and (d.warehouse_id IS NULL OR d.warehouse_id = 10)\n",
        "        ) AB1\n",
        "ON AB1.item_code = A.item_code\n",
        "LEFT JOIN `apna-mart-data.smpublic.smpcm_productsubcategory` x\n",
        "ON A.sub_category_id = x.id\n",
        "-- and b.item_code = 95142\n",
        "-- LIMIT 10\n",
        "''').to_dataframe()"
      ],
      "metadata": {
        "id": "e3dv34TM2VD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WH Stock Query"
      ],
      "metadata": {
        "id": "qpt0inHIJJFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  wh_df2 = pd.read_csv('input wh inventory.csv')\n",
        "  print('input taken')\n",
        "\n",
        "except:\n",
        "  wh_df2 = client.query('''\n",
        "    SELECT X.item_code as sku_code,\n",
        "    X.display_name,\n",
        "    SUM(X.available_for_sale) as wh_qty,\n",
        "    SUM(X.landing_price_inventory_value) as value\n",
        "\n",
        "    FROM (\n",
        "    WITH active_reserved AS (\n",
        "          SELECT ip.warehouse_id,\n",
        "                ib.product_id,\n",
        "                sp.item_code,\n",
        "                sp.display_name,\n",
        "                SUM(ip.qty) AS active_qty,\n",
        "                SUM(reserved_qty) AS reserved_qty,\n",
        "          SUM(ip.qty*ib.landing_price) / NULLIF(SUM(ip.qty), 0) AS avg_landing_price\n",
        "          FROM `apna-mart-data.smpublic.smwims_inventoryplacement` ip\n",
        "          LEFT JOIN `apna-mart-data.smpublic.smwims_inventorybatch` ib ON ib.id = ip.inv_batch_id\n",
        "          LEFT JOIN `apna-mart-data.smpublic.smwms_warehouseshelflevel` wsl ON ip.shelf_lvl_id = wsl.id\n",
        "          LEFT JOIN `apna-mart-data.smpublic.smpcm_product` sp ON ib.product_id = sp.id\n",
        "          WHERE wsl.status = 'LIV'\n",
        "            AND wsl.lifecycle_identifier = 'SEL'\n",
        "            AND wsl.outward_identifier = 'PIK'\n",
        "            AND (((sp.shelf_life > 4 OR sp.shelf_life is null) AND CAST(ib.expiry_date AS DATE) >= CURRENT_DATE + INTERVAL 4 DAY)\n",
        "              OR (sp.shelf_life <= 4 AND (CAST(ib.expiry_date AS DATE) >= CURRENT_DATE))\n",
        "              OR (ib.expiry_date IS NULL))\n",
        "          GROUP BY ip.warehouse_id, ib.product_id, sp.item_code, sp.display_name\n",
        "    ),\n",
        "    fop AS (\n",
        "        SELECT\n",
        "            warehouse_id,\n",
        "            product_id,\n",
        "            SUM(CASE WHEN status = 'REQ' THEN order_qty ELSE 0 END) AS requested_qty,\n",
        "            SUM(CASE WHEN status = 'ORD' THEN order_qty ELSE 0 END) AS open_order_qty\n",
        "        FROM `apna-mart-data.smpublic.smorder_franchiseeorderproduct`\n",
        "        GROUP BY 1,2\n",
        "    ),\n",
        "\n",
        "    stn as (\n",
        "        SELECT\n",
        "          from_warehouse_id,\n",
        "          product_id,\n",
        "          SUM(booked_quantity) as stn_booked\n",
        "        FROM `apna-mart-data.smpublic.smwims_stnrequestedproduct`\n",
        "        WHERE status='APR'\n",
        "        GROUP BY 1,2\n",
        "    )\n",
        "\n",
        "    SELECT ar.warehouse_id, ar.product_id, ar.item_code, ar.display_name,\n",
        "          coalesce(ar.active_qty, 0) AS active_qty,\n",
        "          coalesce(ar.reserved_qty, 0) AS reserved_qty,\n",
        "          coalesce(fop.requested_qty, 0) AS requested_qty,\n",
        "          coalesce(fop.open_order_qty, 0) AS open_order_qty,\n",
        "          coalesce(stn.stn_booked,0) as stn_booked_qty,\n",
        "          GREATEST((coalesce(ar.active_qty, 0) - coalesce(ar.reserved_qty, 0) - coalesce(fop.requested_qty, 0) - coalesce(fop.open_order_qty, 0) -coalesce(stn.stn_booked,0)),0) AS Available_for_sale,\n",
        "          coalesce(ar.avg_landing_price*GREATEST((coalesce(ar.active_qty, 0) - coalesce(ar.reserved_qty, 0) - coalesce(fop.requested_qty, 0) - coalesce(fop.open_order_qty, 0) -coalesce(stn.stn_booked,0)),0),0) as Landing_price_inventory_value\n",
        "    FROM active_reserved ar\n",
        "    LEFT JOIN fop ON fop.product_id = ar.product_id AND ar.warehouse_id = fop.warehouse_id\n",
        "    Left join stn on stn.product_id=ar.product_id and stn.from_warehouse_id=ar.warehouse_id\n",
        "    ) X\n",
        "\n",
        "    WHERE X.warehouse_id = 8 OR X.warehouse_id = 10\n",
        "    GROUP BY 1,2\n",
        "    HAVING SUM(X.available_for_sale) > 0\n",
        "\n",
        "  ''').to_dataframe()"
      ],
      "metadata": {
        "id": "pUKwci6KJI5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtsMiEOgcQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1faaac9-6a40-4707-e3ae-b9db73505a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "store_name is a string column\n",
            "display_name is a string column\n",
            "pending_reason is a string column\n",
            "created_at is a string column\n",
            "brand is a string column\n",
            "status is a string column\n",
            "name is a string column\n",
            "display_name is a string column\n",
            "name is a string column\n",
            "status is a string column\n",
            "display_name is a string column\n",
            "brand is a string column\n",
            "name is a string column\n",
            "level_code is a string column\n",
            "Sub_category is a string column\n",
            "display_name is a string column\n"
          ]
        }
      ],
      "source": [
        "# Converting all numeric columns to Float\n",
        "l1 = [\n",
        "        inv_df2,\n",
        "        avl_df2,\n",
        "        cart_df2,\n",
        "        transit_df2,\n",
        "        mrq_df2,\n",
        "        wh_df2\n",
        "     ]\n",
        "\n",
        "for ele in l1:\n",
        "  for col in ele:\n",
        "    try:\n",
        "      ele[col] = ele[col].astype(np.float32)\n",
        "    except:\n",
        "      print(f'{col} is a string column')\n",
        "\n",
        "cart_df2 = cart_df2.groupby(['item_code','samaan_id'],as_index=False).agg({'order_qty':'sum'})\n",
        "transit_df2 = transit_df2.groupby(['item_code','name'],as_index=False).agg({'process_qty':'sum'})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL Query result Output\n",
        "\n",
        "# inv_df2.to_csv(\"inventory of foco.csv\",index=False)\n",
        "# avl_df2.to_csv(\"available days of foco.csv\",index=False)\n",
        "# cart_df2.to_csv(\"in-cart items of foco.csv\",index=False)\n",
        "# transit_df2.to_csv(\"in-transit items of foco.csv\",index=False)\n",
        "# wh_df2.to_csv(\"wh stock of foco.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "BGLHhJhFpCV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remaining Ordering Sheet"
      ],
      "metadata": {
        "id": "Ck10VCPee9Fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdVHBSUhpjwG"
      },
      "outputs": [],
      "source": [
        "# Store Ordering\n",
        "# Scanning Ordering files from Google Sheet (Automated Store Ordering - Python)\n",
        "\n",
        "# üß† Safe retry function\n",
        "def safe_get_values(ws, rng, max_retries=5):\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            return ws.get_values(rng)\n",
        "        except gspread.exceptions.APIError as e:\n",
        "            if e.response and e.response.status_code == 429:\n",
        "                wait = 2 ** i + random.uniform(0, 1)\n",
        "                print(f\"‚ö†Ô∏è  Quota exceeded. Retrying in {wait:.2f} seconds...\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                raise\n",
        "    raise Exception(\"‚ùå Max retries reached for get_values\")\n",
        "\n",
        "# üßæ Store Ordering\n",
        "raw_df = {}\n",
        "for name in gids.keys():\n",
        "    worksheet = workbook.get_worksheet_by_id(gids[name])\n",
        "    time.sleep(2)  # Pause to avoid rate limit\n",
        "    print(f\"üì• Fetching: {name}\")\n",
        "\n",
        "    rows = safe_get_values(worksheet, 'A2:H')\n",
        "    df_items = pd.DataFrame.from_records(rows)\n",
        "    df_items.columns = ['tez_id','samaan_id','store_name','beat_gap','multiplier','item_code','target_doh','mbq']\n",
        "\n",
        "    df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']] = \\\n",
        "        df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']].replace('', np.nan)\n",
        "\n",
        "    df_items['item_code'] = df_items['item_code'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
        "\n",
        "    df_items = df_items.astype({\n",
        "        'tez_id': np.float16,\n",
        "        'samaan_id': np.float16,\n",
        "        'beat_gap': np.float16,\n",
        "        'multiplier': np.float16,\n",
        "        'item_code': np.float32,\n",
        "        'target_doh': np.float16,\n",
        "        'mbq': np.float16\n",
        "    })\n",
        "\n",
        "    raw_df[name] = df_items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warehouse Ordering\n",
        "\n",
        "# üß† Retry wrapper for quota-safe get_values\n",
        "def safe_get_values(ws, rng, max_retries=5):\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            return ws.get_values(rng)\n",
        "        except gspread.exceptions.APIError as e:\n",
        "            if e.response and e.response.status_code == 429:\n",
        "                wait = 2 ** i + random.uniform(0, 1)\n",
        "                print(f\"‚ö†Ô∏è  Quota exceeded. Retrying in {wait:.2f} seconds...\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                raise\n",
        "    raise Exception(\"‚ùå Max retries reached for get_values\")\n",
        "\n",
        "# üßæ Main warehouse data loop\n",
        "wh_raw_df = {}\n",
        "for name in wh_gids.keys():\n",
        "    worksheet = workbook.get_worksheet_by_id(wh_gids[name])\n",
        "    time.sleep(2)  # ‚úÖ Reduce rapid calls\n",
        "\n",
        "    print(f\"üì• Fetching: {name}\")\n",
        "    rows = safe_get_values(worksheet, 'A2:H')\n",
        "\n",
        "    df_items = pd.DataFrame.from_records(rows)\n",
        "    df_items.columns = ['tez_id','samaan_id','store_name','beat_gap','multiplier','item_code','target_doh','mbq']\n",
        "\n",
        "    df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']] = \\\n",
        "        df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']].replace('', np.nan)\n",
        "\n",
        "    df_items['item_code'] = df_items['item_code'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
        "\n",
        "    df_items = df_items.astype({\n",
        "        'tez_id': np.float16,\n",
        "        'samaan_id': np.float16,\n",
        "        'beat_gap': np.float16,\n",
        "        'multiplier': np.float16,\n",
        "        'item_code': np.float32,\n",
        "        'target_doh': np.float16,\n",
        "        'mbq': np.float16\n",
        "    })\n",
        "\n",
        "    wh_raw_df[name] = df_items"
      ],
      "metadata": {
        "id": "SEKutlHlQgw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etFVnMfunvNi"
      },
      "outputs": [],
      "source": [
        "# GENERATING ORDER Store Order\n",
        "\n",
        "# Making calulations on the basis of given params and Generating Orders\n",
        "\n",
        "names = raw_df.keys()\n",
        "cooked_dfs = {}\n",
        "\n",
        "for ele in names:\n",
        "  print(ele)\n",
        "  cooked_dfs[ele] = dfCreator(raw_df[ele],ele)\n",
        "\n",
        "print(f'Orders are successfully generated!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATING ORDER Warehouse\n",
        "\n",
        "wh_names = wh_raw_df.keys()\n",
        "wh_cooked_dfs = {}\n",
        "\n",
        "for ele in wh_names:\n",
        "  print(ele)\n",
        "  wh_cooked_dfs[ele] = dfCreator(wh_raw_df[ele],ele)\n",
        "\n",
        "print(f'wh_Orders are successfully generated!')"
      ],
      "metadata": {
        "id": "TduSd9Q2TS_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2vlYprTDTuG"
      },
      "outputs": [],
      "source": [
        "# Stacking all columns, compiling complete ordering sheet\n",
        "\n",
        "collated_df = pd.concat(cooked_dfs.values()).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warehouse order collate\n",
        "\n",
        "wh_collated_df = pd.concat(wh_cooked_dfs.values()).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rqzkFpxnUrI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wh_collated_df[wh_collated_df['type'] == 'winter']"
      ],
      "metadata": {
        "id": "2qTT-VIJoPC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oCIPLUPz7wq"
      },
      "outputs": [],
      "source": [
        "# Creating OD File, (i.e. Item x Store x Max Qty)\n",
        "\n",
        "grouped_df = collated_df.groupby(['item_code','store_name'],as_index=False).agg({'order':'max'})\n",
        "for_details = grouped_df.copy()\n",
        "grouped_df = pd.merge(grouped_df,collated_df.loc[:,['item_code','store_name','order','type']],on=['item_code','store_name','order'],how='left')\n",
        "\n",
        "# OD File\n",
        "grouped_df = grouped_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "grouped_df = grouped_df[grouped_df['order'] != 0]\n",
        "\n",
        "# Detailed OD File\n",
        "details_df = pd.merge(for_details,collated_df,on=['item_code','store_name','order'],how='left')\n",
        "details_df = details_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "details_df = details_df[details_df['order'] != 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Warehouse Order\n",
        "\n",
        "wh_grouped_df = wh_collated_df.groupby(['item_code','store_name'],as_index=False).agg({'order':'max'})\n",
        "# for_details = wh_grouped_df.copy()\n",
        "\n",
        "# Adding Type column\n",
        "wh_grouped_df = pd.merge(wh_grouped_df,wh_collated_df.loc[:,['item_code','store_name','order','type']],on=['item_code','store_name','order'],how='left')\n",
        "\n",
        "# Dropping Duplicates\n",
        "wh_grouped_df = wh_grouped_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "\n",
        "# Removing zeros\n",
        "# wh_grouped_df = wh_grouped_df[wh_grouped_df['order'] != 0]"
      ],
      "metadata": {
        "id": "8FmR4YcdU2_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exclusion Part"
      ],
      "metadata": {
        "id": "Zl6fekkLsFm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exclusionList = workbook.get_worksheet_by_id(156791444)\n",
        "rows = exclusionList.get_values('A2:C')\n",
        "ex_items = pd.DataFrame.from_records(rows)\n",
        "ex_items = ex_items[[1, 2]]\n",
        "ex_items.columns = ['store_name','item_code']\n",
        "ex_items.loc[:,['store_name','item_code']].replace(to_replace='',value=np.nan,inplace=True)\n",
        "ex_items['item_code'] = ex_items['item_code'].apply(lambda x: x.replace(',',''))\n",
        "ex_items = ex_items.astype({'item_code':np.float32})\n",
        "\n",
        "# Create a boolean mask for rows to keep (not in ex_items)\n",
        "ex_items = ~grouped_df[['store_name', 'item_code']].apply(tuple, axis=1).isin(ex_items[['store_name', 'item_code']].apply(tuple, axis=1))\n",
        "\n",
        "# Apply the mask\n",
        "grouped_df = grouped_df[ex_items]"
      ],
      "metadata": {
        "id": "DFU01M8QsJ9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Part"
      ],
      "metadata": {
        "id": "MysXSinSsWuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the Google Sheet and select the specified worksheet\n",
        "specified_worksheet = workbook.worksheet(\"Store Order\")  # Change to your target sheet name\n",
        "\n",
        "# Clear the specific range in the specified worksheet\n",
        "specified_worksheet.batch_clear([\"A2:D\"])  # Adjust the range as needed\n",
        "\n",
        "# Write the raw collated DataFrame to the specified worksheet\n",
        "set_with_dataframe(specified_worksheet, grouped_df, include_index=False, include_column_header=True, row=2, col=1)\n",
        "\n",
        "print(\"‚úÖ Successfully cleared the specified range and updated with store order.\")"
      ],
      "metadata": {
        "id": "ABLnOfbGeZWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasting Store Demand in Automated Store Ordering CG sheet\n",
        "\n",
        "# Get the target sheet\n",
        "ordering_sheet = gc.open('Automated Store Ordering ' + state_name)\n",
        "output_sheet = ordering_sheet.get_worksheet_by_id(499483054)\n",
        "\n",
        "# Build the warehouse demand DataFrame\n",
        "warehouse_demand_df = wh_grouped_df.groupby(['item_code'], as_index=False).agg({'order': 'sum'})\n",
        "\n",
        "# üßπ Clear previous output cleanly\n",
        "output_sheet.batch_clear(['A2:B'])\n",
        "\n",
        "# üì• Paste new output with headers at A2\n",
        "output_sheet.update(\n",
        "    [warehouse_demand_df.columns.tolist()] + warehouse_demand_df.values.tolist(),\n",
        "    \"A2\"\n",
        ")"
      ],
      "metadata": {
        "id": "OaWIhryvOhGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "R17u4AdWeZtV",
        "T1ooJgv4qgb7",
        "LGKoIrzkuoK9",
        "Cd9dXXBJy96n",
        "ApNVAirG2VV4",
        "Ck10VCPee9Fx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
