{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "state_name = 'WB'\n",
        "state_full_name = 'West Bengal'\n",
        "warehouse_id_1 = 8\n",
        "warehouse_id_2 = 10"
      ],
      "metadata": {
        "id": "7EJIx6NWmIr9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ajawLrQWBrJS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import gspread\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from datetime import datetime as dt\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from googleapiclient.http import MediaFileUpload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xGUfhldroGdd"
      },
      "outputs": [],
      "source": [
        "# ✅ 1. Load credentials from Colab Secrets\n",
        "secret_string = userdata.get(\"gspread_credentials\")\n",
        "info_dict = json.loads(secret_string)\n",
        "\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = service_account.Credentials.from_service_account_info(info_dict, scopes=SCOPES)\n",
        "\n",
        "# ✅ 2. Authorize gspread\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ✅ 3. Open the Google Sheet (make sure it's shared with service account)\n",
        "workbook = gc.open(f\"Automated Store Ordering {state_name} PY - 2\")\n",
        "\n",
        "# ✅ 4. Used here for Drive API\n",
        "drive_service = build(\"drive\", \"v3\", credentials=creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclusion store from 60 DOH Capping\n",
        "\n",
        "exclusion_stores = ['AM Barasat KOL', 'AM Sonar Mandir HM KOL']"
      ],
      "metadata": {
        "id": "kMOv8F9eFb6u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gmrwrY3A-kcX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def repeat_stores(input_list, n):\n",
        "    # Convert the list to a numpy array\n",
        "    array = np.array(input_list)\n",
        "\n",
        "    # Using numpy's repeat function to repeat each element\n",
        "    repeated_array = np.repeat(array, n, 0)\n",
        "\n",
        "    return repeated_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ikFuxgwUBR7U"
      },
      "outputs": [],
      "source": [
        "def mround(number, multiple):\n",
        "  return round(number / multiple + 0.0001) * multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XEQKYsp1Zk-Q"
      },
      "outputs": [],
      "source": [
        "def makeOrder(curre_qty, ars, tres_doh, tar_doh, modi_mbq, mrq, ct_name, st_name):\n",
        "    # Equation 1: MBQ + DOH with 1\n",
        "    if ct_name == 'Sankranti':\n",
        "        if (curre_qty / ars) > tres_doh and curre_qty >= modi_mbq:\n",
        "            return 0\n",
        "        else:\n",
        "            return mround(\n",
        "                math.ceil(\n",
        "                    max(((tar_doh - (curre_qty / ars)) * ars) - 0.00001,\n",
        "                        (max(modi_mbq, mrq) - curre_qty)) / 2\n",
        "                ) * 2,\n",
        "                mrq\n",
        "            )\n",
        "\n",
        "    # Equation 2: MBQ Only\n",
        "    elif ct_name in ['clip_strip', 'bcd', 'super_deals', 'wow_week', 'mt', 'mt_ad_hoc', 'visibility', 'gift', 'focus_skus', 'asm']:\n",
        "        mbq_only = max(math.ceil(((modi_mbq - curre_qty) / mrq) - 0.00001) * mrq, 0)\n",
        "\n",
        "        # Apply safeguard if DOH >= 60\n",
        "        if (mbq_only + curre_qty) / ars >= 60 and st_name not in exclusion_stores and ct_name not in ['mt', 'visibility', 'gift']:\n",
        "            if curre_qty == 0:\n",
        "                return 2\n",
        "            elif (curre_qty / ars) >= 60:\n",
        "                return 0\n",
        "            else:\n",
        "                return math.ceil(max(((60 - (curre_qty / ars)) * ars) - 0.00001, 1))\n",
        "        else:\n",
        "            return mbq_only\n",
        "\n",
        "    # Equation 3: MBQ + DOH with 1.5\n",
        "    else:\n",
        "        if (curre_qty / ars) > tres_doh and curre_qty >= (modi_mbq / 1.5):\n",
        "            return 0\n",
        "        else:\n",
        "            final_qty = mround(\n",
        "                math.ceil(\n",
        "                    max(((tar_doh - (curre_qty / ars)) * ars) - 0.00001,\n",
        "                        (max(modi_mbq, mrq) - curre_qty)) / 2\n",
        "                ) * 2,\n",
        "                mrq\n",
        "            )\n",
        "\n",
        "            # Apply safeguard if DOH >= 60\n",
        "            if (final_qty + curre_qty) / ars >= 60 and st_name not in exclusion_stores and ct_name not in ['loose']:\n",
        "                if curre_qty == 0:\n",
        "                    return 2\n",
        "                elif (curre_qty / ars) >= 60:\n",
        "                    return 0\n",
        "                else:\n",
        "                    return math.ceil(max(((60 - (curre_qty / ars)) * ars) - 0.00001, 1))\n",
        "            else:\n",
        "                return final_qty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "udRmzRYNQLUJ"
      },
      "outputs": [],
      "source": [
        "def cal_thres(beat,tar,cat):\n",
        "  if cat == 'fmcg_a' or cat == 'fmcg_b' or cat == 'fmcg_c' or cat == 'staples_a' or cat == 'staples_b' or cat == 'staples_c' or cat == 'gm_a' or cat == 'gm_b' or cat == 'gm_c' or cat == 'loose' or cat == 'jit' or cat == 'jit-k' or cat == 'summer' or cat == 'btl' or cat == 'npi' or cat == 'clip_strip' or cat == 'bcd' or cat == 'super_deals' or cat == 'wow_week' or cat == 'mt' or cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'gift' or cat == 'focus_skus' or cat == 'asm' or cat == 'allocation' or cat == 'depletion':\n",
        "    return beat + tar\n",
        "  # elif cat in ('non-core'):\n",
        "  #   return round(tar/2)\n",
        "  else:\n",
        "    return beat + 3\n",
        "\n",
        "def cal_tar(thres,tar,cat):\n",
        "  # if cat == 'fmcg_head' or cat == 'staples' or cat == 'staples_jit' or cat == 'loose':\n",
        "  if cat == 'fmcg_a' or cat == 'fmcg_b' or cat == 'fmcg_c' or cat == 'staples_a' or cat == 'staples_b' or cat == 'staples_c' or cat == 'gm_a' or cat == 'gm_b' or cat == 'gm_c' or cat == 'loose' or cat == 'jit' or cat == 'jit-k' or cat == 'summer' or cat == 'btl' or cat == 'npi' or cat == 'clip_strip' or cat == 'bcd' or cat == 'super_deals' or cat == 'wow_week' or cat == 'mt' or cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'gift' or cat == 'focus_skus' or cat == 'asm' or cat == 'allocation' or cat == 'depletion':\n",
        "    return thres\n",
        "  # elif cat in ('non-core'):\n",
        "  #   return tar\n",
        "  else:\n",
        "    return thres + tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "umY3Z__RC1gd"
      },
      "outputs": [],
      "source": [
        "def cal_mbq(multiplier, mbq, cat):\n",
        "  if cat == 'mt_ad_hoc' or cat == 'visibility' or cat == 'loose':\n",
        "    return mbq\n",
        "  elif cat == 'gift':\n",
        "    return round(multiplier*mbq,1)\n",
        "  else:\n",
        "    return mround((multiplier*mbq),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SoEnvBAcQYEr"
      },
      "outputs": [],
      "source": [
        "def dfCreator(cat_df,cat_name):\n",
        "  # creating store x item list\n",
        "\n",
        "  if cat_name == 'mt_ad_hoc' or cat_name == 'visibility' or cat_name == 'gift':\n",
        "    joined_df1 = cat_df\n",
        "  else:\n",
        "    st_details = cat_df.loc[:,[\"tez_id\",\"samaan_id\",\"store_name\",\"beat_gap\",\"multiplier\"]]\n",
        "    st_details = st_details[st_details['tez_id'] != 0]\n",
        "    it_details = cat_df.loc[:,[\"item_code\",\"target_doh\",\"mbq\"]]\n",
        "    it_details = it_details[it_details['item_code'] != 0]\n",
        "    st_half = pd.DataFrame(repeat_stores(st_details,it_details.shape[0]),columns=st_details.columns)\n",
        "    it_half = pd.DataFrame(np.tile(np.array(it_details),(st_details.shape[0],1)),columns=it_details.columns)\n",
        "    joined_df1 = st_half.join(it_half)\n",
        "\n",
        "\n",
        "  joined_df1['type'] = cat_name\n",
        "  joined_df1['multiplier'] = joined_df1['multiplier'].apply(lambda x: np.around(x,1))\n",
        "  joined_df1['mod_mbq'] = joined_df1.apply(lambda x: cal_mbq(x['multiplier'],x['mbq'],cat_name),axis=1)\n",
        "  joined_df1 = pd.merge(joined_df1,mrq_df2.loc[:,['item_code','display_name','min_replenish_qty']],on=['item_code'],how='left')\n",
        "  print('merge 1')\n",
        "  joined_df1 = pd.merge(joined_df1,inv_df2,on=['store_name','item_code'],how='left')\n",
        "  print('merge 2')\n",
        "  transit_df2.rename(columns={'name':'store_name'},inplace=True)\n",
        "  joined_df1 = pd.merge(joined_df1,transit_df2.loc[:,['store_name','item_code','process_qty']],on=['store_name','item_code'],how='left')\n",
        "  print('merge 3')\n",
        "  # cart_df.rename(columns={'store_id':'samaan_id'},inplace=True)\n",
        "  # joined_df1 = pd.merge(joined_df1,cart_df2,on=['samaan_id','item_code'],how='left')\n",
        "  print('merge 4')\n",
        "  joined_df1 = pd.merge(joined_df1,avl_df2,left_on=['tez_id','item_code'],right_on=['store_id','item_code'],how='left')\n",
        "  print('merge 5')\n",
        "  joined_df1.drop(columns=['store_id'],inplace=True)\n",
        "  joined_df1['curr_qty'] = joined_df1['curr_qty'].fillna(0)\n",
        "  joined_df1['process_qty'] = joined_df1['process_qty'].fillna(0)\n",
        "  # joined_df1['order_qty'] = joined_df1['order_qty'].fillna(0)\n",
        "  joined_df1['count_avl_days'] = joined_df1['count_avl_days'].fillna(0.01)\n",
        "  joined_df1['count_avl_days'] = joined_df1['count_avl_days'].apply(lambda x: 15 if x < 15 else x)\n",
        "  joined_df1['last_30daysales'] = joined_df1['last_30daysales'].fillna(0.01)\n",
        "  joined_df1['last_30daysales'] = joined_df1['last_30daysales'].apply(lambda x: x if x > 0 else 0.01)\n",
        "  # joined_df1 = joined_df1.assign(all_qty=lambda row: row['curr_qty'] + row['process_qty'] + row['order_qty']) # Calculating All qty\n",
        "  joined_df1 = joined_df1.assign(all_qty=lambda row: row['curr_qty'] + row['process_qty']) # Calculating All qty\n",
        "  joined_df1 = joined_df1.assign(curr_doh=lambda row: row['curr_qty']/(row['last_30daysales']/row['count_avl_days'])) # Calculating curr DOH\n",
        "  # joined_df1.drop(columns=['curr_qty','process_qty','order_qty'],inplace=True) # Removing Extra Columns\n",
        "  joined_df1.drop(columns=['curr_qty','process_qty'],inplace=True) # Removing Extra Columns\n",
        "  joined_df1 = joined_df1.assign(ARS=lambda x: x['last_30daysales']/x['count_avl_days'])\n",
        "  joined_df1['ARS'] = joined_df1['ARS'].apply(lambda x: max(x,0.01))\n",
        "\n",
        "  # Calculating Threshold and Target DOH\n",
        "\n",
        "  joined_df1['threshold_doh'] = joined_df1.apply(lambda x: cal_thres(x['beat_gap'],x['target_doh'],cat_name),axis=1)\n",
        "  joined_df1['target_doh'] = joined_df1.apply(lambda x: cal_tar(x['threshold_doh'],x['target_doh'],cat_name) ,axis=1)\n",
        "  joined_df1 = pd.merge(joined_df1,wh_df2.loc[:,['sku_code','wh_qty']],left_on=['item_code'],right_on=['sku_code'],how='left')\n",
        "  print('merge 6')\n",
        "  joined_df1['wh_qty'] = joined_df1['wh_qty'].fillna(0)\n",
        "\n",
        "  # print(joined_df1)\n",
        "  joined_df1['order'] = joined_df1.apply(lambda x: makeOrder(x['all_qty'],x['ARS'],x['threshold_doh'],x['target_doh'],x['mod_mbq'],x['min_replenish_qty'],cat_name,x['store_name']),axis=1)\n",
        "\n",
        "  # return joined_df1[joined_df1['order'] != 0].loc[:,['item_code','store_name','order','type']]\n",
        "  # return joined_df1[joined_df1['order'] != 0]\n",
        "  return joined_df1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PL76Nl_2_2sB"
      },
      "outputs": [],
      "source": [
        "# Ordering sheet selections by the user\n",
        "gids = {\n",
        "        ##### Main Assortment #####\n",
        "\n",
        "        'fmcg_a':2140842897,\n",
        "        'fmcg_b':1459512030,\n",
        "        'fmcg_c':1024514954,\n",
        "        'staples_a':686195830,\n",
        "        'staples_b':2098196922,\n",
        "        'staples_c':965871084,\n",
        "        'gm_a':1645717487,\n",
        "        'gm_b':941148715,\n",
        "        'gm_c':314829402,\n",
        "        'loose':53967786,\n",
        "        'jit':197437796,\n",
        "        'jit-k':1553249338,\n",
        "\n",
        "        ##### Temp Assortment #####\n",
        "\n",
        "        'clip_strip':55763387,\n",
        "        'bcd':279157190,\n",
        "        'visibility':1994951969,\n",
        "        'gift':1080084985,\n",
        "        'npi':788140546,\n",
        "        'summer':168005917,\n",
        "        'asm':2075309652,\n",
        "        'focus_skus':960399022,\n",
        "\n",
        "      # 'btl':0,\n",
        "      # 'super_deals':360075548,\n",
        "      # 'wow_week':2111882564,\n",
        "      # 'mt':440498050,\n",
        "      # 'mt_ad_hoc':913226990,\n",
        "      # 'allocation':341955460,\n",
        "      # 'depletion':1974209973\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wh_gids = {\n",
        "        ##### Main Assortment #####\n",
        "\n",
        "        'fmcg_a':2140842897,\n",
        "        'fmcg_b':1459512030,\n",
        "        'fmcg_c':1024514954,\n",
        "        'staples_a':686195830,\n",
        "        'staples_b':2098196922,\n",
        "        'staples_c':965871084,\n",
        "        'gm_a':1645717487,\n",
        "        'gm_b':941148715,\n",
        "        'gm_c':314829402,\n",
        "        'loose':53967786,\n",
        "        'jit':197437796,\n",
        "        'jit-k':1553249338,\n",
        "\n",
        "        ##### Temp Assortment #####\n",
        "\n",
        "        'clip_strip':55763387,\n",
        "        'bcd':279157190,\n",
        "        'npi':788140546,\n",
        "        'summer':168005917,\n",
        "        'asm':2075309652,\n",
        "        'focus_skus':960399022,\n",
        "\n",
        "      # 'btl':0,\n",
        "      # 'super_deals':360075548,\n",
        "      # 'wow_week':2111882564,\n",
        "      # 'mt':440498050,\n",
        "      # 'mt_ad_hoc':913226990,\n",
        "      # 'visibility':1994951969,\n",
        "      # 'gift':1080084985,\n",
        "      # 'allocation':341955460,\n",
        "      # 'depletion':1974209973\n",
        "        }"
      ],
      "metadata": {
        "id": "PCBVoBtsLYLK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataBase Inputs"
      ],
      "metadata": {
        "id": "R17u4AdWeZtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### DB Imports #########\n",
        "\n",
        "sheet_id = '1f-Ty8gMlzi1fvm8wpNdX7GFjqHk9pytI5eGtvTpvc2Q'\n",
        "gids_import = {\n",
        "    \"Avl Days\": \"0\",\n",
        "    \"Inventory of foco\": \"1706153079\",\n",
        "    \"MRQ and Price\": \"1884639423\",\n",
        "    \"Transit\": \"514474300\",\n",
        "    \"Warehouse Inventory\": \"1325392378\"\n",
        "}\n",
        "\n",
        "### Inventory of foco ###\n",
        "try:\n",
        "    inv_df2 = pd.read_csv('input inventory of foco.csv')\n",
        "    print('input taken: inventory of foco')\n",
        "except:\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gids_import['Inventory of foco']}\"\n",
        "    inv_df2 = pd.read_csv(url)\n",
        "    print('Loaded from Google Sheet: Inventory of foco')\n",
        "\n",
        "### Avl Days ###\n",
        "try:\n",
        "    avl_df2 = pd.read_csv('input available days of foco.csv')\n",
        "    print('input taken: avl days')\n",
        "except:\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gids_import['Avl Days']}\"\n",
        "    avl_df2 = pd.read_csv(url)\n",
        "    print('Loaded from Google Sheet: Avl Days')\n",
        "\n",
        "### Transit ###\n",
        "try:\n",
        "    transit_df2 = pd.read_csv('input in-transit items of foco.csv')\n",
        "    print('input taken: transit')\n",
        "except:\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gids_import['Transit']}\"\n",
        "    transit_df2 = pd.read_csv(url)\n",
        "    print('Loaded from Google Sheet: Transit')\n",
        "\n",
        "### MRQ and Price ###\n",
        "try:\n",
        "    mrq_df2 = pd.read_csv('input mrq and price.csv')\n",
        "    print('input taken: MRQ and Price')\n",
        "except:\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gids_import['MRQ and Price']}\"\n",
        "    mrq_df2 = pd.read_csv(url)\n",
        "    print('Loaded from Google Sheet: MRQ and Price')\n",
        "\n",
        "### Warehouse Inventory ###\n",
        "try:\n",
        "    wh_df2 = pd.read_csv('input wh inventory.csv')\n",
        "    print('input taken: warehouse inventory')\n",
        "except:\n",
        "    url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gids_import['Warehouse Inventory']}\"\n",
        "    wh_df2 = pd.read_csv(url)\n",
        "    print('Loaded from Google Sheet: Warehouse Inventory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFKBm8UuuZiA",
        "outputId": "4c333842-a602-4687-bcec-dd4a4cc8af48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded from Google Sheet: Inventory of foco\n",
            "Loaded from Google Sheet: Avl Days\n",
            "Loaded from Google Sheet: Transit\n",
            "Loaded from Google Sheet: MRQ and Price\n",
            "Loaded from Google Sheet: Warehouse Inventory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JtsMiEOgcQDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8184a44-8ac7-45b0-a846-fd6b64a66357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "store_name is a string column\n",
            "display_name is a string column\n",
            "name is a string column\n",
            "status is a string column\n",
            "display_name is a string column\n",
            "master_category is a string column\n",
            "category is a string column\n",
            "sub_category is a string column\n",
            "leaf_category is a string column\n",
            "product_type is a string column\n",
            "display_name is a string column\n"
          ]
        }
      ],
      "source": [
        "# Converting all numeric columns to Float\n",
        "l1 = [\n",
        "        inv_df2,\n",
        "        avl_df2,\n",
        "        # cart_df2,\n",
        "        transit_df2,\n",
        "        mrq_df2,\n",
        "        wh_df2\n",
        "     ]\n",
        "\n",
        "for ele in l1:\n",
        "  for col in ele:\n",
        "    try:\n",
        "      ele[col] = ele[col].astype(np.float32)\n",
        "    except:\n",
        "      print(f'{col} is a string column')\n",
        "\n",
        "# cart_df2 = cart_df2.groupby(['item_code','samaan_id'],as_index=False).agg({'order_qty':'sum'})\n",
        "transit_df2 = transit_df2.groupby(['item_code','name'],as_index=False).agg({'process_qty':'sum'})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL Query result Output\n",
        "\n",
        "# inv_df2.to_csv(\"inventory of foco.csv\",index=False)\n",
        "# avl_df2.to_csv(\"available days of foco.csv\",index=False)\n",
        "# cart_df2.to_csv(\"in-cart items of foco.csv\",index=False)\n",
        "# transit_df2.to_csv(\"in-transit items of foco.csv\",index=False)\n",
        "# wh_df2.to_csv(\"wh stock of foco.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "BGLHhJhFpCV5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remaining Ordering Sheet"
      ],
      "metadata": {
        "id": "Ck10VCPee9Fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kdVHBSUhpjwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7081edfe-1448-434d-a290-bd7e41d9fda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Fetching: fmcg_a\n",
            "📥 Fetching: fmcg_b\n",
            "📥 Fetching: fmcg_c\n",
            "📥 Fetching: staples_a\n",
            "📥 Fetching: staples_b\n",
            "📥 Fetching: staples_c\n",
            "📥 Fetching: gm_a\n",
            "📥 Fetching: gm_b\n",
            "📥 Fetching: gm_c\n",
            "📥 Fetching: loose\n",
            "📥 Fetching: jit\n",
            "📥 Fetching: jit-k\n",
            "📥 Fetching: clip_strip\n",
            "📥 Fetching: bcd\n",
            "📥 Fetching: visibility\n",
            "📥 Fetching: gift\n",
            "📥 Fetching: npi\n",
            "📥 Fetching: summer\n",
            "📥 Fetching: asm\n",
            "📥 Fetching: focus_skus\n"
          ]
        }
      ],
      "source": [
        "# Store Ordering\n",
        "# Scanning Ordering files from Google Sheet (Automated Store Ordering - Python)\n",
        "# Safe retry function\n",
        "def safe_get_values(ws, rng, max_retries=5):\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            return ws.get_values(rng)\n",
        "        except Exception as e:\n",
        "            if '429' in str(e):\n",
        "                wait = 2 ** i + random.uniform(0, 1)\n",
        "                print(f\"⚠️  Quota exceeded. Retrying in {wait:.2f} seconds...\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                raise\n",
        "    raise Exception(\"❌ Max retries reached for get_values\")\n",
        "\n",
        "# 🧾 Store Ordering\n",
        "raw_df = {}\n",
        "for name in gids.keys():\n",
        "    worksheet = workbook.get_worksheet_by_id(gids[name])\n",
        "    time.sleep(1)  # Pause to avoid rate limit\n",
        "    print(f\"📥 Fetching: {name}\")\n",
        "\n",
        "    rows = safe_get_values(worksheet, 'A2:H')\n",
        "    df_items = pd.DataFrame.from_records(rows)\n",
        "    df_items.columns = ['tez_id','samaan_id','store_name','beat_gap','multiplier','item_code','target_doh','mbq']\n",
        "\n",
        "    df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']] = \\\n",
        "        df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']].replace('', np.nan)\n",
        "\n",
        "    df_items['item_code'] = df_items['item_code'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
        "\n",
        "    df_items = df_items.astype({\n",
        "        'tez_id': np.float16,\n",
        "        'samaan_id': np.float16,\n",
        "        'beat_gap': np.float16,\n",
        "        'multiplier': np.float16,\n",
        "        'item_code': np.float32,\n",
        "        'target_doh': np.float16,\n",
        "        'mbq': np.float16\n",
        "    })\n",
        "\n",
        "    raw_df[name] = df_items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warehouse Ordering\n",
        "\n",
        "# 🧠 Retry wrapper for quota-safe get_values\n",
        "def safe_get_values(ws, rng, max_retries=5):\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            return ws.get_values(rng)\n",
        "        except Exception as e:\n",
        "            if '429' in str(e):\n",
        "                wait = 2 ** i + random.uniform(0, 1)\n",
        "                print(f\"⏳ Quota exceeded. Retrying in {wait:.2f} seconds...\")\n",
        "                time.sleep(wait)\n",
        "            else:\n",
        "                raise\n",
        "    raise Exception(\"🚨 Max retries reached for get_values.\")\n",
        "\n",
        "# 🧾 Main warehouse data loop\n",
        "wh_raw_df = {}\n",
        "for name in wh_gids.keys():\n",
        "    worksheet = workbook.get_worksheet_by_id(wh_gids[name])\n",
        "    time.sleep(1)  # ✅ Reduce rapid calls\n",
        "\n",
        "    print(f\"📥 Fetching: {name}\")\n",
        "    rows = safe_get_values(worksheet, 'A2:H')\n",
        "\n",
        "    df_items = pd.DataFrame.from_records(rows)\n",
        "    df_items.columns = ['tez_id','samaan_id','store_name','beat_gap','multiplier','item_code','target_doh','mbq']\n",
        "\n",
        "    df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']] = \\\n",
        "        df_items.loc[:, ['tez_id','samaan_id','beat_gap','multiplier','item_code','target_doh','mbq']].replace('', np.nan)\n",
        "\n",
        "    df_items['item_code'] = df_items['item_code'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x)\n",
        "\n",
        "    df_items = df_items.astype({\n",
        "        'tez_id': np.float16,\n",
        "        'samaan_id': np.float16,\n",
        "        'beat_gap': np.float16,\n",
        "        'multiplier': np.float16,\n",
        "        'item_code': np.float32,\n",
        "        'target_doh': np.float16,\n",
        "        'mbq': np.float16\n",
        "    })\n",
        "\n",
        "    wh_raw_df[name] = df_items"
      ],
      "metadata": {
        "id": "SEKutlHlQgw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3eb650d-cc05-498f-cefc-000bdb3c3689"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Fetching: fmcg_a\n",
            "📥 Fetching: fmcg_b\n",
            "📥 Fetching: fmcg_c\n",
            "📥 Fetching: staples_a\n",
            "📥 Fetching: staples_b\n",
            "📥 Fetching: staples_c\n",
            "📥 Fetching: gm_a\n",
            "📥 Fetching: gm_b\n",
            "📥 Fetching: gm_c\n",
            "📥 Fetching: loose\n",
            "📥 Fetching: jit\n",
            "📥 Fetching: jit-k\n",
            "📥 Fetching: clip_strip\n",
            "📥 Fetching: bcd\n",
            "📥 Fetching: npi\n",
            "📥 Fetching: summer\n",
            "📥 Fetching: asm\n",
            "📥 Fetching: focus_skus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "etFVnMfunvNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798cf480-95db-4189-a813-6611f535805c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fmcg_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "fmcg_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "fmcg_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "loose\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "jit\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "jit-k\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "clip_strip\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "bcd\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "visibility\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gift\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "npi\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "summer\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "asm\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "focus_skus\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "Orders are successfully generated!\n"
          ]
        }
      ],
      "source": [
        "# GENERATING ORDER Store Order\n",
        "\n",
        "# Making calulations on the basis of given params and Generating Orders\n",
        "\n",
        "names = raw_df.keys()\n",
        "cooked_dfs = {}\n",
        "\n",
        "for ele in names:\n",
        "  print(ele)\n",
        "  cooked_dfs[ele] = dfCreator(raw_df[ele],ele)\n",
        "\n",
        "print(f'Orders are successfully generated!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATING ORDER Warehouse\n",
        "\n",
        "wh_names = wh_raw_df.keys()\n",
        "wh_cooked_dfs = {}\n",
        "\n",
        "for ele in wh_names:\n",
        "  print(ele)\n",
        "  wh_cooked_dfs[ele] = dfCreator(wh_raw_df[ele],ele)\n",
        "\n",
        "print(f'wh_Orders are successfully generated!')"
      ],
      "metadata": {
        "id": "TduSd9Q2TS_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61987d05-bee9-44b6-8349-2b37540047b6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fmcg_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "fmcg_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "fmcg_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "staples_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_a\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_b\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "gm_c\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "loose\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "jit\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "jit-k\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "clip_strip\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "bcd\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "npi\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "summer\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "asm\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "focus_skus\n",
            "merge 1\n",
            "merge 2\n",
            "merge 3\n",
            "merge 4\n",
            "merge 5\n",
            "merge 6\n",
            "wh_Orders are successfully generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "H2vlYprTDTuG"
      },
      "outputs": [],
      "source": [
        "# Stacking all columns, compiling complete ordering sheet\n",
        "\n",
        "collated_df = pd.concat(cooked_dfs.values()).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warehouse order collate\n",
        "\n",
        "wh_collated_df = pd.concat(wh_cooked_dfs.values()).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rqzkFpxnUrI-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wh_collated_df[wh_collated_df['type'] == 'winter']"
      ],
      "metadata": {
        "id": "2qTT-VIJoPC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "e773b7ef-90fa-4f3f-918e-fd1a289e2c1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [tez_id, samaan_id, store_name, beat_gap, multiplier, item_code, target_doh, mbq, type, mod_mbq, display_name, min_replenish_qty, last_30daysales, count_avl_days, all_qty, curr_doh, ARS, threshold_doh, sku_code, wh_qty, order]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c08e338d-90a4-40a3-9489-01deb819204a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tez_id</th>\n",
              "      <th>samaan_id</th>\n",
              "      <th>store_name</th>\n",
              "      <th>beat_gap</th>\n",
              "      <th>multiplier</th>\n",
              "      <th>item_code</th>\n",
              "      <th>target_doh</th>\n",
              "      <th>mbq</th>\n",
              "      <th>type</th>\n",
              "      <th>mod_mbq</th>\n",
              "      <th>...</th>\n",
              "      <th>min_replenish_qty</th>\n",
              "      <th>last_30daysales</th>\n",
              "      <th>count_avl_days</th>\n",
              "      <th>all_qty</th>\n",
              "      <th>curr_doh</th>\n",
              "      <th>ARS</th>\n",
              "      <th>threshold_doh</th>\n",
              "      <th>sku_code</th>\n",
              "      <th>wh_qty</th>\n",
              "      <th>order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c08e338d-90a4-40a3-9489-01deb819204a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c08e338d-90a4-40a3-9489-01deb819204a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c08e338d-90a4-40a3-9489-01deb819204a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0oCIPLUPz7wq"
      },
      "outputs": [],
      "source": [
        "# Creating OD File, (i.e. Item x Store x Max Qty)\n",
        "\n",
        "grouped_df = collated_df.groupby(['item_code','store_name'],as_index=False).agg({'order':'max'})\n",
        "for_details = grouped_df.copy()\n",
        "grouped_df = pd.merge(grouped_df,collated_df.loc[:,['item_code','store_name','order','type']],on=['item_code','store_name','order'],how='left')\n",
        "\n",
        "# OD File\n",
        "grouped_df = grouped_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "grouped_df = grouped_df[grouped_df['order'] != 0]\n",
        "\n",
        "# Detailed OD File\n",
        "details_df = pd.merge(for_details,collated_df,on=['item_code','store_name','order'],how='left')\n",
        "details_df = details_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "details_df = details_df[details_df['order'] != 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Warehouse Order\n",
        "\n",
        "wh_grouped_df = wh_collated_df.groupby(['item_code','store_name'],as_index=False).agg({'order':'max'})\n",
        "# for_details = wh_grouped_df.copy()\n",
        "\n",
        "# Adding Type column\n",
        "wh_grouped_df = pd.merge(wh_grouped_df,wh_collated_df.loc[:,['item_code','store_name','order','type']],on=['item_code','store_name','order'],how='left')\n",
        "\n",
        "# Dropping Duplicates\n",
        "wh_grouped_df = wh_grouped_df.drop_duplicates(subset=['item_code','store_name','order'])\n",
        "\n",
        "# Removing zeros\n",
        "# wh_grouped_df = wh_grouped_df[wh_grouped_df['order'] != 0]"
      ],
      "metadata": {
        "id": "8FmR4YcdU2_4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exclusion Part"
      ],
      "metadata": {
        "id": "Zl6fekkLsFm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exclusionList = workbook.get_worksheet_by_id(156791444)\n",
        "rows = exclusionList.get_values('A2:C')\n",
        "ex_items = pd.DataFrame.from_records(rows)\n",
        "ex_items = ex_items[[1, 2]]\n",
        "ex_items.columns = ['store_name','item_code']\n",
        "ex_items.loc[:,['store_name','item_code']].replace(to_replace='',value=np.nan,inplace=True)\n",
        "ex_items['item_code'] = ex_items['item_code'].apply(lambda x: x.replace(',',''))\n",
        "ex_items = ex_items.astype({'item_code':np.float32})\n",
        "\n",
        "# Create a boolean mask for rows to keep (not in ex_items)\n",
        "ex_items = ~grouped_df[['store_name', 'item_code']].apply(tuple, axis=1).isin(ex_items[['store_name', 'item_code']].apply(tuple, axis=1))\n",
        "\n",
        "# Apply the mask\n",
        "grouped_df = grouped_df[ex_items]"
      ],
      "metadata": {
        "id": "DFU01M8QsJ9f"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Part"
      ],
      "metadata": {
        "id": "MysXSinSsWuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-NF4nnjOpljI"
      },
      "outputs": [],
      "source": [
        "# Compiled OD file to CSV\n",
        "grouped_df.to_csv('od_output.csv',index=False)\n",
        "\n",
        "# Compiled Detail OD file to CSV\n",
        "# details_df.to_csv('od_details_output.csv',index=False)\n",
        "\n",
        "# Compiled complete ordering sheet to CSV\n",
        "collated_df.to_csv('complete_output.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ File already saved earlier\n",
        "local_path = '/content/complete_output.csv'\n",
        "\n",
        "# ✅ Just change the filename in Drive, not locally\n",
        "new_filename = f\"complete_details_{str(dt.today().date())}.csv\"\n",
        "\n",
        "# ✅ Upload to Drive\n",
        "folder_id = \"1ZY8tCyVrFLz36rVw0kx4eMObf781OS2d\"  # Replace with your Drive folder ID\n",
        "\n",
        "file_metadata = {\n",
        "    'name': new_filename,\n",
        "    'parents': [folder_id]\n",
        "}\n",
        "\n",
        "media = MediaFileUpload(local_path, mimetype='text/csv')\n",
        "\n",
        "file = drive_service.files().create(\n",
        "    body=file_metadata,\n",
        "    media_body=media,\n",
        "    fields='id'\n",
        ").execute()\n",
        "\n",
        "print(\"complete_output uploaded to drive\")"
      ],
      "metadata": {
        "id": "T4V0kch9sgw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1ced1e-226f-4a66-9fc9-3f21efab14c9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "complete_output uploaded to drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the Google Sheet and select the specified worksheet\n",
        "specified_worksheet = workbook.worksheet(\"Store Order\")  # Change to your target sheet name\n",
        "\n",
        "# Clear the specific range in the specified worksheet\n",
        "specified_worksheet.batch_clear([\"A2:D\"])  # Adjust the range as needed\n",
        "\n",
        "# Write the raw collated DataFrame to the specified worksheet\n",
        "set_with_dataframe(specified_worksheet, grouped_df, include_index=False, include_column_header=True, row=2, col=1)\n",
        "\n",
        "print(\"✅ Successfully cleared the specified range and updated with store order.\")"
      ],
      "metadata": {
        "id": "ABLnOfbGeZWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd3797e-1227-4977-cc02-95d27cd90c4b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully cleared the specified range and updated with store order.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GLNb-Sv7K-yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca37b0f-440b-43cb-97e9-e1a6e1fa7d8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1SjnzZybBzCUZozqrEIhF2PKnm-SYHTCaALQYjm5oVvY',\n",
              " 'updatedRange': \"'Warehouse Order'!A2:B4780\",\n",
              " 'updatedRows': 4779,\n",
              " 'updatedColumns': 2,\n",
              " 'updatedCells': 9558}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Pasting Store Demand in Automated Store Ordering CG sheet\n",
        "\n",
        "output_sheet = workbook.get_worksheet_by_id(1789363742)\n",
        "cell_list = output_sheet.get_values('A2:B')\n",
        "\n",
        "tempi_df = pd.DataFrame.from_records(cell_list)\n",
        "\n",
        "size = tempi_df.shape\n",
        "\n",
        "wh_grouped_df.to_csv('warehouse_output.csv',index=False)\n",
        "warehouse_demand_df = wh_grouped_df.groupby(['item_code'],as_index=False).agg({'order':'sum'})\n",
        "\n",
        "# Deleting Previous Output\n",
        "\n",
        "check = np.full(size,'')\n",
        "output_sheet.update(pd.DataFrame(check).values.tolist(),\"A2\")\n",
        "\n",
        "# Pasting new Output\n",
        "\n",
        "warehouse_demand_df = wh_grouped_df.groupby(['item_code'],as_index=False).agg({'order':'sum'})\n",
        "output_sheet.update(warehouse_demand_df.values.tolist(),\"A2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# warehouse_demand_df.to_csv('warehouse_demand.csv',index=False)"
      ],
      "metadata": {
        "id": "OH3tD3bnvBbw"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zsxLKJtVo5-W",
        "T1ooJgv4qgb7",
        "LGKoIrzkuoK9",
        "ApNVAirG2VV4",
        "qpt0inHIJJFX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
